{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 50 candidates, totalling 150 fits\n",
      "Best Parameters: {'subsample': 0.9, 'n_estimators': 200, 'min_child_weight': 1, 'max_depth': 5, 'learning_rate': 0.10666666666666666, 'colsample_bytree': 0.7999999999999999}\n",
      "Best R-squared Score from CV: 0.6494\n",
      "Mean Squared Error (MSE) with Best Model: 868293910.0715\n",
      "Mean Absolute Error (MAE) with Best Model: 21278.6007\n",
      "R-squared (R2) with Best Model: 0.6580\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "dtf = pd.read_csv(\"./survey_results_minimal.csv\",index_col='ResponseId', encoding='utf-8')\n",
    "\n",
    "filtered_dtf = dtf.copy()\n",
    "\n",
    "\n",
    "filtered_dtf.loc[:, 'YearsCodePro'] = pd.to_numeric(filtered_dtf['YearsCodePro'], errors='coerce')\n",
    "filtered_dtf.loc[:, 'YearsCode'] = pd.to_numeric(filtered_dtf['YearsCode'], errors='coerce')\n",
    "\n",
    "categorical_columns = ['MainBranch','Age', 'RemoteWork', 'EdLevel', 'DevType', 'OrgSize', 'Country', 'Industry','ICorPM']\n",
    "categorical_dtf =filtered_dtf.copy()\n",
    "\n",
    "label_encoder_dict = {}\n",
    "\n",
    "\n",
    "for col in categorical_columns:\n",
    "    label_encoder = LabelEncoder()  # Create a new LabelEncoder for each column\n",
    "    categorical_dtf[col] = label_encoder.fit_transform(categorical_dtf[col].astype(str))\n",
    "    label_encoder_dict[col] = label_encoder  # Store the encoder for future use\n",
    "\n",
    "x=1.5\n",
    "Q1 = categorical_dtf['ConvertedCompYearly'].quantile(0.25)\n",
    "Q3 = categorical_dtf['ConvertedCompYearly'].quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "upper_bound = Q3 + x * IQR\n",
    "\n",
    "categorical_dtf = categorical_dtf[(categorical_dtf['ConvertedCompYearly'] <= upper_bound)]\n",
    "\n",
    "categorical_dtf = categorical_dtf.astype(float).fillna(0)\n",
    "categorical_dtf.to_csv('categorical_dtf.csv', index=True, header=True)\n",
    "\n",
    "# Define features (X) and target (y) for the top 10 countries\n",
    "X_top = categorical_dtf.drop(columns=['ConvertedCompYearly'])  # Features\n",
    "y_top = categorical_dtf['ConvertedCompYearly']  # Target\n",
    "\n",
    "# Define the parameter distribution\n",
    "param_dist = {\n",
    "    'n_estimators': [50, 100, 150, 200],\n",
    "    'learning_rate': np.linspace(0.01, 0.3, 10),  # Spread learning rates\n",
    "    'max_depth': [3, 5, 7, 10],\n",
    "    'min_child_weight': [1, 3, 5],\n",
    "    'subsample': np.linspace(0.7, 1.0, 4),        # More granular subsample rates\n",
    "    'colsample_bytree': np.linspace(0.7, 1.0, 4),\n",
    "}\n",
    "\n",
    "# Initialize the model\n",
    "xgb_model = XGBRegressor(objective='reg:squarederror', random_state=42)\n",
    "\n",
    "# Initialize RandomizedSearchCV\n",
    "random_search = RandomizedSearchCV(\n",
    "    estimator=xgb_model,\n",
    "    param_distributions=param_dist,\n",
    "    n_iter=50,                # Test 50 random combinations\n",
    "    scoring='r2',             # Optimize for R-squared\n",
    "    cv=3,                     # 3-fold cross-validation\n",
    "    verbose=1,\n",
    "    n_jobs=-1,                # Use all cores\n",
    "    random_state=42           # Ensure reproducibility\n",
    ")\n",
    "\n",
    "# Perform the random search\n",
    "X_train_top, X_test_top, y_train_top, y_test_top = train_test_split(X_top, y_top, test_size=0.2, random_state=42)\n",
    "random_search.fit(X_train_top, y_train_top)\n",
    "\n",
    "# Best parameters and performance\n",
    "best_params = random_search.best_params_\n",
    "best_score = random_search.best_score_\n",
    "\n",
    "print(f\"Best Parameters: {best_params}\")\n",
    "print(f\"Best R-squared Score from CV: {best_score:.4f}\")\n",
    "\n",
    "# Train the model with best parameters\n",
    "best_model = random_search.best_estimator_\n",
    "best_model.fit(X_train_top, y_train_top)\n",
    "\n",
    "# Evaluate on the test set\n",
    "y_pred_best = best_model.predict(X_test_top)\n",
    "\n",
    "mse_best = mean_squared_error(y_test_top, y_pred_best)\n",
    "mae_best = mean_absolute_error(y_test_top, y_pred_best)\n",
    "r2_best = r2_score(y_test_top, y_pred_best)\n",
    "\n",
    "print(f\"Mean Squared Error (MSE) with Best Model: {mse_best:.4f}\")\n",
    "print(f\"Mean Absolute Error (MAE) with Best Model: {mae_best:.4f}\")\n",
    "print(f\"R-squared (R2) with Best Model: {r2_best:.4f}\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recommend_skills_individual_with_best_value(user_profile, model, X_columns, X_data, label_encoder_dict, top_n=5):\n",
    "    \"\"\"\n",
    "    Generate automatic top N skill recommendations with estimated salary impact for an individual,\n",
    "    by testing all possible values for each feature and determining which gives the best salary prediction.\n",
    "    \n",
    "    user_profile: A pandas Series or numpy array containing the individual's features (skills, experience, etc.)\n",
    "    model: The trained model (e.g., XGBRegressor)\n",
    "    X_columns: The list of feature column names\n",
    "    X_data: The original feature data (for getting the unique values of each feature)\n",
    "    label_encoder_dict: Dictionary of LabelEncoders for categorical features\n",
    "    top_n: The number of recommendations to provide\n",
    "    \n",
    "    Returns the current salary and a list of skill improvement recommendations with salary impact.\n",
    "    \"\"\"\n",
    "    # Predict the individual's current salary\n",
    "    current_salary = model.predict(user_profile.reshape(1, -1))[0]\n",
    "    \n",
    "    recommendations = []\n",
    "    \n",
    "    # Iterate through all features to calculate the salary impact of improving each feature\n",
    "    for i, feature in enumerate(X_columns):\n",
    "        feature_value = user_profile[i]\n",
    "        \n",
    "        # Get all unique values for this feature from the data\n",
    "        unique_values = np.unique(X_data[feature])\n",
    "        \n",
    "        # Initialize variables to track the best result for this feature\n",
    "        best_value = feature_value\n",
    "        best_salary = current_salary\n",
    "        best_salary_increase = 0\n",
    "        \n",
    "        # Simulate changing this feature to each possible value\n",
    "        for value in unique_values:\n",
    "            # Create a copy of the user profile to simulate the change in this feature\n",
    "            user_profile_copy = user_profile.copy()\n",
    "            \n",
    "            # Set the feature value to the candidate value\n",
    "            user_profile_copy[i] = value\n",
    "            \n",
    "            # Predict the new salary after the change\n",
    "            improved_salary = model.predict(user_profile_copy.reshape(1, -1))[0]\n",
    "            \n",
    "            # Calculate the salary increase\n",
    "            salary_increase = improved_salary - current_salary\n",
    "            \n",
    "            # If this value gives a better salary, update the best value\n",
    "            if salary_increase > best_salary_increase:\n",
    "                best_value = value\n",
    "                best_salary = improved_salary\n",
    "                best_salary_increase = salary_increase\n",
    "        \n",
    "        # If the feature is categorical and has a label encoder, decode the value back to its original label\n",
    "        if feature in label_encoder_dict:\n",
    "            encoder = label_encoder_dict[feature]\n",
    "            # Convert best_value to integer for inverse_transform\n",
    "            best_value_int = int(best_value)\n",
    "            best_value_str = encoder.inverse_transform([best_value_int])[0]\n",
    "        else:\n",
    "            best_value_str = best_value\n",
    "        \n",
    "        # Generate the recommendation\n",
    "        recommendation = f\"Change your {feature} to {best_value_str} to increase your salary by approximately ${best_salary_increase:.2f}.\"\n",
    "        recommendations.append((best_value_str, best_salary_increase, recommendation))\n",
    "    \n",
    "    # Sort the recommendations by the salary increase, descending order\n",
    "    recommendations.sort(key=lambda x: x[1], reverse=True)\n",
    "    \n",
    "    # Return the current salary and top N recommendations\n",
    "    top_recommendations = [recommendation[2] for recommendation in recommendations[:top_n]]\n",
    "    return current_salary, top_recommendations\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user_profile: [  0.   0.   0.   5.   3.   1.   5.   3. 112.   1.   3.  13.  10.   1.\n",
      "   0.   1.   1.   1.   1.   1.   1.   1.   1.   1.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   1.   1.   1.   1.   0.   0.   0.   0.]\n"
     ]
    }
   ],
   "source": [
    "user_profile = X_top.iloc[0].values  # Get the first individual's data from the test set\n",
    "\n",
    "current_salary, skills_recommendations = recommend_skills_individual_with_best_value(\n",
    "    user_profile, best_model, X_top.columns, X_top, label_encoder_dict, top_n=1000)\n",
    "print(f\"user_profile: {user_profile}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['label_encoders.pkl']"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "\n",
    "# Save the trained model to a file\n",
    "joblib.dump(best_model, 'model.pkl')\n",
    "joblib.dump(label_encoder_dict, 'label_encoders.pkl')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
